{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20852033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import pandas as pd\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab87a8a0",
   "metadata": {},
   "source": [
    "https://www.scrapingdog.com/blog/scrape-linkedin-jobs/\n",
    "\n",
    "https://www.geeksforgeeks.org/using-jupyter-notebook-in-virtual-environment/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf5be33",
   "metadata": {},
   "source": [
    "# Target URL\n",
    "Follow the steps to produce a target URL:\n",
    "1. Goto Linkedin and search for a job with any filters you want.\n",
    "2. Open up the Developer inspector (Use Google Chrome) and scroll down until the next set of jobs load.\n",
    "3. In the network tab there should be a \"search\" request when it loads the new jobs.\n",
    "4. Grab that URL in the search request.\n",
    "5. replace the last NUMBER in the URL with a {} in order to utilize a .format() for looping later. ie 'start=0' -> 'start={}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecae2de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_url = 'https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=Data%2BScientist&location=United%2BStates&geoId=103644278&f_JT=F&f_E=2&f_WT=2&currentJobId=3664087381&position=1&pageNum=0&start={}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3cd035",
   "metadata": {},
   "source": [
    "# Job ID Loop\n",
    "Used to get the Job ID to appened to the job URL for crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "828d8b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_id_scrape(target_url, num_of_jobs):\n",
    "    l=[] #Empty list to store job IDs. These IDs are used to create the URLs for specific job searches later\n",
    "    a = 0 #Used for the URL page number\n",
    "    pattern = 'jobPosting:(?P<job_id>\\d+)' #Regex patter to get the job ID\n",
    "    for i in range(0, math.ceil(num_of_jobs/25)): #Use math.ceil() to round off the loop, the numerator can be found by looking at the filters when building the target URL.\n",
    "        res = requests.get(target_url.format(a)) #Get request against the target URL and a .format() in order to provide specific page number.\n",
    "        a += 25\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        all_jobs = soup.find_all('li') #The 'li' tag contains the job ID\n",
    "        #print(len(all_jobs)) #Debug\n",
    "        for j in range(0, len(all_jobs)): #Loop through all b4 'li' list\n",
    "            job_id = re.search(pattern, str(all_jobs[j])) #Using Regex to search for the ID\n",
    "            l.append(int(job_id.groups()[0])) #Appened the ID and casting it as int for later use.\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0b73fb63-7641-4a06-9ea8-50ea4d0324d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "job_ids = job_id_scrape(target_url, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cb093534-e423-43c0-b16b-d3444b1707bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3695796378,\n",
       " 3664087381,\n",
       " 3695796357,\n",
       " 3624206900,\n",
       " 3632360327,\n",
       " 3695790928,\n",
       " 3693849036,\n",
       " 3603332905,\n",
       " 3627030054,\n",
       " 3695809550,\n",
       " 3685291387,\n",
       " 3695792590,\n",
       " 3695829145,\n",
       " 3653339410,\n",
       " 3648295510,\n",
       " 3674709878,\n",
       " 3692136204,\n",
       " 3693865409,\n",
       " 3695792577,\n",
       " 3686134894,\n",
       " 3683935408,\n",
       " 3635642191,\n",
       " 3673021599,\n",
       " 3684851788]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fb12ff",
   "metadata": {},
   "source": [
    "# Job Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "035dc7f7-de1c-4afd-8d76-b7c03c0fe885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_scrape(job_id_list):\n",
    "    df = {'job_title' : [], 'company' : [], 'job_info' : [], 'when_posted' : [], 'num_applicants' : [],\n",
    "          'seniority' : [], 'employment_type' : [], 'job_function' : [], 'industry' : []}\n",
    "    target_job_url = 'https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/{}/' #format of the URL. The {} is where the jobID gets formated to.\n",
    "    for i in range(0, len(job_id_list)): # Main loop\n",
    "        res_job = requests.get(target_job_url.format(job_id_list[i]))\n",
    "        soup = BeautifulSoup(res_job.text, 'html.parser')\n",
    "        try:\n",
    "            df['job_title'].append(soup.find('div',{'class':'top-card-layout__entity-info'}).find('a').text.strip()) #Title\n",
    "        except:\n",
    "            df['job_title'].append(None)\n",
    "        try:\n",
    "            df['company'].append(soup.find('div',{'class':'top-card-layout__card'}).find('a').find('img').get('alt')) #Company\n",
    "        except:\n",
    "            df['company'].append(None)\n",
    "        try:\n",
    "            df['job_info'].append(soup.find('div',{'class':'show-more-less-html__markup'}).text.strip()) #Bulk, might need to find a way to clean this up.\n",
    "        except:\n",
    "            df['job_info'].append(None)\n",
    "        try:\n",
    "            df['when_posted'].append(soup.find('span',{'class':'posted-time-ago__text'}).text.replace('\\n', '').strip()) #When was it posted\n",
    "        except:\n",
    "            df['when_posted'].append(None)\n",
    "        num_of_apps1 = soup.find('figcaption',{'class':'num-applicants__caption'})  #number of applicants scape attempt1\n",
    "        if num_of_apps1 == None: #Check first soup, if it fails check second soup\n",
    "            num_of_apps2 = soup.find('span', class_='num-applicants__caption topcard__flavor--metadata topcard__flavor--bullet') #number of applicants scrape attempt2\n",
    "            if num_of_apps2 == None: #Check second soup, if it fails, append None\n",
    "                df['num_applicants'].append(None) #if nosoup works just append None\n",
    "            else:\n",
    "                df['num_applicants'].append(num_of_apps2.text.replace('\\n', '').strip()) #If first soup failed and second soup passed, append second soup\n",
    "        else:\n",
    "            df['num_applicants'].append(num_of_apps1.text.replace('\\n', '').strip()) #If first soup works, append first soup\n",
    "        job_attributes = soup.find('ul',{'class':'description__job-criteria-list'}) #Job attributes\n",
    "        if job_attributes == None: #Check to see if there is soup. If not, pass.\n",
    "            pass\n",
    "        else:\n",
    "            job_attributes = job_attributes.text.replace('\\n', '').strip()\n",
    "            pattern = 'Seniority level\\s+(?P<seniority>.*?)\\s\\s+Employment type\\s+(?P<job_type>.*?)\\s\\s+Job function\\s+(?P<job_function>.*?)\\s\\s+Industries\\s+(?P<industry>.*)'\n",
    "            job_attributes = re.search(pattern, job_attributes).groups()\n",
    "            df['seniority'].append(job_attributes[0]) #Seniority\n",
    "            df['employment_type'].append(job_attributes[1]) #Employment type\n",
    "            df['job_function'].append(job_attributes[2]) #Job function\n",
    "            df['industry'].append(job_attributes[3]) #Industry\n",
    "        time.sleep(random.choice(range(3,8,1))) # Sleep to avoid IP block\n",
    "    return pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9fbc282c-7f61-4bbb-b5f5-214518878f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = job_scrape(job_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8aa3b496-a2cf-499b-bcf3-ced5e67a713f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>job_info</th>\n",
       "      <th>when_posted</th>\n",
       "      <th>num_applicants</th>\n",
       "      <th>seniority</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_function</th>\n",
       "      <th>industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist (Entry Level)</td>\n",
       "      <td>Pattern Learning AI - Career &amp; Tech Recruitmen...</td>\n",
       "      <td>This is a remote position.Data Scientist (Entr...</td>\n",
       "      <td>2 hours ago</td>\n",
       "      <td>66 applicants</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Software Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Analytica</td>\n",
       "      <td>Analytica is seeking a remoteData Scientistto ...</td>\n",
       "      <td>1 month ago</td>\n",
       "      <td>Over 200 applicants</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist (Entry Level) - US</td>\n",
       "      <td>Pattern Learning AI - Career &amp; Tech Recruitmen...</td>\n",
       "      <td>This is a remote position.Data Scientist (Entr...</td>\n",
       "      <td>2 hours ago</td>\n",
       "      <td>Be among the first 25 applicants</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Software Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>QuantumBricks</td>\n",
       "      <td>Job Title: Data scientistLoc: RemoteExp: 9+ Yr...</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>Over 200 applicants</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Strategy</td>\n",
       "      <td>Agero, Inc.</td>\n",
       "      <td>About Agero:Wherever drivers go, we’re leading...</td>\n",
       "      <td>3 weeks ago</td>\n",
       "      <td>Over 200 applicants</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           job_title  \\\n",
       "0       Data Scientist (Entry Level)   \n",
       "1                     Data Scientist   \n",
       "2  Data Scientist (Entry Level) - US   \n",
       "3                     Data Scientist   \n",
       "4          Data Scientist - Strategy   \n",
       "\n",
       "                                             company  \\\n",
       "0  Pattern Learning AI - Career & Tech Recruitmen...   \n",
       "1                                          Analytica   \n",
       "2  Pattern Learning AI - Career & Tech Recruitmen...   \n",
       "3                                      QuantumBricks   \n",
       "4                                        Agero, Inc.   \n",
       "\n",
       "                                            job_info   when_posted  \\\n",
       "0  This is a remote position.Data Scientist (Entr...   2 hours ago   \n",
       "1  Analytica is seeking a remoteData Scientistto ...   1 month ago   \n",
       "2  This is a remote position.Data Scientist (Entr...   2 hours ago   \n",
       "3  Job Title: Data scientistLoc: RemoteExp: 9+ Yr...  2 months ago   \n",
       "4  About Agero:Wherever drivers go, we’re leading...   3 weeks ago   \n",
       "\n",
       "                     num_applicants    seniority employment_type  \\\n",
       "0                     66 applicants  Entry level       Full-time   \n",
       "1               Over 200 applicants  Entry level       Full-time   \n",
       "2  Be among the first 25 applicants  Entry level       Full-time   \n",
       "3               Over 200 applicants  Entry level       Full-time   \n",
       "4               Over 200 applicants  Entry level       Full-time   \n",
       "\n",
       "                             job_function                       industry  \n",
       "0  Engineering and Information Technology           Software Development  \n",
       "1  Engineering and Information Technology  IT Services and IT Consulting  \n",
       "2  Engineering and Information Technology           Software Development  \n",
       "3  Engineering and Information Technology  IT Services and IT Consulting  \n",
       "4  Engineering and Information Technology  IT Services and IT Consulting  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c6ea047b-2e9e-4b37-9fab-093e542d7c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24 entries, 0 to 23\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   job_title        24 non-null     object\n",
      " 1   company          24 non-null     object\n",
      " 2   job_info         24 non-null     object\n",
      " 3   when_posted      24 non-null     object\n",
      " 4   num_applicants   24 non-null     object\n",
      " 5   seniority        24 non-null     object\n",
      " 6   employment_type  24 non-null     object\n",
      " 7   job_function     24 non-null     object\n",
      " 8   industry         24 non-null     object\n",
      "dtypes: object(9)\n",
      "memory usage: 1.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envlinkedin",
   "language": "python",
   "name": "envlinkedin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
