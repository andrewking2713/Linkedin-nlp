{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20852033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import pandas as pd\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab87a8a0",
   "metadata": {},
   "source": [
    "https://www.scrapingdog.com/blog/scrape-linkedin-jobs/\n",
    "\n",
    "https://www.geeksforgeeks.org/using-jupyter-notebook-in-virtual-environment/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf5be33",
   "metadata": {},
   "source": [
    "# Target URL\n",
    "Follow the steps to produce a target URL:\n",
    "1. Goto Linkedin and search for a job with any filters you want.\n",
    "2. Open up the Developer inspector (Use Google Chrome) and scroll down until the next set of jobs load.\n",
    "3. In the network tab there should be a \"search\" request when it loads the new jobs.\n",
    "4. Grab that URL in the search request.\n",
    "5. replace the last NUMBER in the URL with a {} in order to utilize a .format() for looping later. ie 'start=0' -> 'start={}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecae2de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_url = 'https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=Data%2BScientist&location=United%2BStates&geoId=103644278&f_TPR=r86400&f_JT=F&f_E=2%2C4&f_WT=2&currentJobId=3692555868&position=2&pageNum=2&start={}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3cd035",
   "metadata": {},
   "source": [
    "# Job ID Loop\n",
    "Used to get the Job ID to appened to the job URL for crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "828d8b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_id_scrape(target_url, num_of_jobs):\n",
    "    l=[] #Empty list to store job IDs. These IDs are used to create the URLs for specific job searches later\n",
    "    a = 0 #Used for the URL page number\n",
    "    pattern = 'jobPosting:(?P<job_id>\\d+)' #Regex patter to get the job ID\n",
    "    for i in range(0, math.ceil(num_of_jobs/25)): #Use math.ceil() to round off the loop, the numerator can be found by looking at the filters when building the target URL.\n",
    "        res = requests.get(target_url.format(a)) #Get request against the target URL and a .format() in order to provide specific page number.\n",
    "        a += 25\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        all_jobs = soup.find_all('li') #The 'li' tag contains the job ID\n",
    "        #print(len(all_jobs)) #Debug\n",
    "        for j in range(0, len(all_jobs)): #Loop through all b4 'li' list\n",
    "            job_id = re.search(pattern, str(all_jobs[j])) #Using Regex to search for the ID\n",
    "            l.append(int(job_id.groups()[0])) #Appened the ID and casting it as int for later use.\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b73fb63-7641-4a06-9ea8-50ea4d0324d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "job_ids_list = job_id_scrape(target_url, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f96355c4-bb66-4ff7-b3c7-5ea4ce186db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "975"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_ids_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fb12ff",
   "metadata": {},
   "source": [
    "# Job Loop\n",
    "This is made outside of a function on purpose because if the function fails at any step it won't return a DF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "035dc7f7-de1c-4afd-8d76-b7c03c0fe885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obatined info for id: 3691869782\n",
      "Obatined info for id: 3696159081\n",
      "Obatined info for id: 3692553497\n",
      "Obatined info for id: 3695130693\n",
      "Obatined info for id: 3696143316\n",
      "Obatined info for id: 3691836860\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 69\u001b[0m\n\u001b[1;32m     67\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(job_ids_list[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     68\u001b[0m job_ids_list\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = {'job_title' : [], 'company' : [], 'job_info' : [], 'when_posted' : [], 'num_applicants' : [],\n",
    "      'seniority' : [], 'employment_type' : [], 'job_function' : [], 'industry' : [], 'job_id' : []}\n",
    "target_job_url = 'https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/{}/' #format of the URL. The {} is where the jobID gets formated to.\n",
    "for i in range(0, len(job_ids_list)): # Main loop\n",
    "    res_job = requests.get(target_job_url.format(job_ids_list[i]))\n",
    "    soup = BeautifulSoup(res_job.text, 'html.parser')\n",
    "    try:\n",
    "        df['job_title'].append(soup.find('div',{'class':'top-card-layout__entity-info'}).find('a').text.strip()) #Title\n",
    "    except:\n",
    "        df['job_title'].append(None)\n",
    "    try:\n",
    "        df['company'].append(soup.find('div',{'class':'top-card-layout__card'}).find('a').find('img').get('alt')) #Company\n",
    "    except:\n",
    "        df['company'].append(None)\n",
    "    try:\n",
    "        df['job_info'].append(soup.find('div',{'class':'show-more-less-html__markup'}).text.strip()) #Bulk, might need to find a way to clean this up.\n",
    "    except:\n",
    "        df['job_info'].append(None)\n",
    "    try:\n",
    "        df['when_posted'].append(soup.find('span',{'class':'posted-time-ago__text'}).text.replace('\\n', '').strip()) #When was it posted\n",
    "    except:\n",
    "        df['when_posted'].append(None)\n",
    "    num_of_apps1 = soup.find('figcaption',{'class':'num-applicants__caption'})  #number of applicants scape attempt1\n",
    "    if num_of_apps1 == None: #Check first soup, if it fails check second soup\n",
    "        num_of_apps2 = soup.find('span', class_='num-applicants__caption topcard__flavor--metadata topcard__flavor--bullet') #number of applicants scrape attempt2\n",
    "        if num_of_apps2 == None: #Check second soup, if it fails, append None\n",
    "            df['num_applicants'].append(None) #if nosoup works just append None\n",
    "        else:\n",
    "            df['num_applicants'].append(num_of_apps2.text.replace('\\n', '').strip()) #If first soup failed and second soup passed, append second soup\n",
    "    else:\n",
    "        df['num_applicants'].append(num_of_apps1.text.replace('\\n', '').strip()) #If first soup works, append first soup\n",
    "    job_attributes = soup.find('ul',{'class':'description__job-criteria-list'}) #Job attributes\n",
    "    if job_attributes == None: #Check to see if there is soup. If not, pass.\n",
    "        df['seniority'].append(None)\n",
    "        df['employment_type'].append(None)\n",
    "        df['job_function'].append(None)\n",
    "        df['industry'].append(None)\n",
    "    else:\n",
    "        job_attributes = job_attributes.text.replace('\\n', '').strip()\n",
    "        if 'Seniority level' in job_attributes:\n",
    "            pattern = 'Seniority level\\s+(?P<seniority>[a-zA-z!@#$%^&*()-]+\\s[a-zA-z!@#$%^&*()-]*)'\n",
    "            df['seniority'].append(re.search(pattern, test_string).groups()[0])\n",
    "        else:\n",
    "            df['seniority'].append(None)\n",
    "        if 'Employment type' in job_attributes:\n",
    "            pattern = 'Employment type\\s+(?P<employment_type>[a-zA-z!@#$%^&*()-]+\\s[a-zA-z!@#$%^&*()-]*)'\n",
    "            df['employment_type'].append(re.search(pattern, test_string).groups()[0])\n",
    "        else:\n",
    "            df['employment_type'].append(None)\n",
    "        if 'Job function' in job_attributes:\n",
    "            pattern = 'Job function\\s+(?P<job_function>[a-zA-z!@#$%^&*()-]+\\s[a-zA-z!@#$%^&*()-]*)'\n",
    "            df['job_function'].append(re.search(pattern, test_string).groups()[0])\n",
    "        else:\n",
    "            df['job_function'].append(None)\n",
    "        if 'Industries' in job_attributes:\n",
    "            pattern = 'Industries\\s+(?P<industries>[a-zA-z!@#$%^&*()-]+\\s[a-zA-z!@#$%^&*()-]*)'\n",
    "            df['industry'].append(re.search(pattern, test_string).groups()[0])\n",
    "        else:\n",
    "            df['industry'].append(None)\n",
    "    print(f'Obatined info for id: {job_ids_list[i]}')\n",
    "    df['job_id'].append(job_ids_list[0])\n",
    "    job_ids_list.pop(0)\n",
    "    time.sleep(random.choice(range(3,5,1))) # Sleep to avoid IP block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8aa3b496-a2cf-499b-bcf3-ced5e67a713f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>job_info</th>\n",
       "      <th>when_posted</th>\n",
       "      <th>num_applicants</th>\n",
       "      <th>seniority</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_function</th>\n",
       "      <th>industry</th>\n",
       "      <th>job_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist, gt.school (Remote) - $60,000/y...</td>\n",
       "      <td>Crossover</td>\n",
       "      <td>Crossover is the world's #1 source of full-tim...</td>\n",
       "      <td>19 hours ago</td>\n",
       "      <td>Be among the first 25 applicants</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>3691869782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>Deepgram</td>\n",
       "      <td>Company OverviewDeepgram is a foundational AI ...</td>\n",
       "      <td>1 hour ago</td>\n",
       "      <td>Be among the first 25 applicants</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>3696142461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remote - Application Developer</td>\n",
       "      <td>Sonitalent Corp</td>\n",
       "      <td>Job Role: Application DeveloperDuration: 6 mon...</td>\n",
       "      <td>2 hours ago</td>\n",
       "      <td>Be among the first 25 applicants</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>3696159081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Associate Software Engineer (Remote)</td>\n",
       "      <td>Patterson Companies, Inc.</td>\n",
       "      <td>Dolphin Imaging Systems has a great opportunit...</td>\n",
       "      <td>19 hours ago</td>\n",
       "      <td>169 applicants</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>3689951639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Junior Mobile App Developer</td>\n",
       "      <td>Pattern Learning AI - Career &amp; Tech Recruitmen...</td>\n",
       "      <td>This is a remote position.Junior Mobile App De...</td>\n",
       "      <td>2 hours ago</td>\n",
       "      <td>Be among the first 25 applicants</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>3692553497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0  Data Scientist, gt.school (Remote) - $60,000/y...   \n",
       "1                                 Research Scientist   \n",
       "2                     Remote - Application Developer   \n",
       "3               Associate Software Engineer (Remote)   \n",
       "4                        Junior Mobile App Developer   \n",
       "\n",
       "                                             company  \\\n",
       "0                                         Crossover    \n",
       "1                                           Deepgram   \n",
       "2                                    Sonitalent Corp   \n",
       "3                          Patterson Companies, Inc.   \n",
       "4  Pattern Learning AI - Career & Tech Recruitmen...   \n",
       "\n",
       "                                            job_info   when_posted  \\\n",
       "0  Crossover is the world's #1 source of full-tim...  19 hours ago   \n",
       "1  Company OverviewDeepgram is a foundational AI ...    1 hour ago   \n",
       "2  Job Role: Application DeveloperDuration: 6 mon...   2 hours ago   \n",
       "3  Dolphin Imaging Systems has a great opportunit...  19 hours ago   \n",
       "4  This is a remote position.Junior Mobile App De...   2 hours ago   \n",
       "\n",
       "                     num_applicants    seniority employment_type  \\\n",
       "0  Be among the first 25 applicants  Entry level      Full-time    \n",
       "1  Be among the first 25 applicants  Entry level      Full-time    \n",
       "2  Be among the first 25 applicants  Entry level      Full-time    \n",
       "3                    169 applicants  Entry level      Full-time    \n",
       "4  Be among the first 25 applicants  Entry level      Full-time    \n",
       "\n",
       "      job_function              industry      job_id  \n",
       "0  Engineering and  Software Development  3691869782  \n",
       "1  Engineering and  Software Development  3696142461  \n",
       "2  Engineering and  Software Development  3696159081  \n",
       "3  Engineering and  Software Development  3689951639  \n",
       "4  Engineering and  Software Development  3692553497  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c6ea047b-2e9e-4b37-9fab-093e542d7c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6 entries, 0 to 5\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   job_title        6 non-null      object\n",
      " 1   company          6 non-null      object\n",
      " 2   job_info         6 non-null      object\n",
      " 3   when_posted      6 non-null      object\n",
      " 4   num_applicants   6 non-null      object\n",
      " 5   seniority        6 non-null      object\n",
      " 6   employment_type  6 non-null      object\n",
      " 7   job_function     6 non-null      object\n",
      " 8   industry         6 non-null      object\n",
      " 9   job_id           6 non-null      int64 \n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 612.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09ac6c8-e4be-4242-b429-79c5ed603c99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envlinkedin",
   "language": "python",
   "name": "envlinkedin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
