{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20852033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "import wrangle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab87a8a0",
   "metadata": {},
   "source": [
    "https://www.scrapingdog.com/blog/scrape-linkedin-jobs/\n",
    "\n",
    "https://www.geeksforgeeks.org/using-jupyter-notebook-in-virtual-environment/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf5be33",
   "metadata": {},
   "source": [
    "# Target URL\n",
    "Follow the steps to produce a target URL:\n",
    "1. Goto Linkedin and search for a job with any filters you want.\n",
    "2. Open up the Developer inspector (Use Google Chrome) and scroll down until the next set of jobs load.\n",
    "3. In the network tab there should be a \"search\" request when it loads the new jobs.\n",
    "4. Grab that URL in the search request.\n",
    "5. replace the last NUMBER in the URL with a {} in order to utilize a .format() for looping later. ie 'start=0' -> 'start={}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecae2de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_url = 'https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=Data%2BScientist&location=United%2BStates&geoId=103644278&f_TPR=r86400&f_JT=F&f_E=2%2C4&f_WT=2&currentJobId=3692555868&position=2&pageNum=2&start={}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3cd035",
   "metadata": {},
   "source": [
    "# Job ID Loop\n",
    "Used to get the Job ID to appened to the job URL for crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b73fb63-7641-4a06-9ea8-50ea4d0324d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "job_ids_list = wrangle.job_id_scrape(target_url, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f96355c4-bb66-4ff7-b3c7-5ea4ce186db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "973"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_ids_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fb12ff",
   "metadata": {},
   "source": [
    "# Job Loop\n",
    "This is made outside of a function on purpose because if the function fails or is interupted at any step it won't return a DF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "035dc7f7-de1c-4afd-8d76-b7c03c0fe885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obatined info for id: 3696204960\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'groups'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 56\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJob function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m job_attributes:\n\u001b[1;32m     55\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJob function\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+(?P<job_function>[a-zA-z!@#$\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m^&*()-]+\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms[a-zA-z!@#$\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m^&*()-]*)\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 56\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob_function\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_attributes\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m()[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob_function\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'groups'"
     ]
    }
   ],
   "source": [
    "\n",
    "df = {'job_title' : [], 'company' : [], 'job_info' : [], 'when_posted' : [], 'num_applicants' : [],\n",
    "      'seniority' : [], 'employment_type' : [], 'job_function' : [], 'industry' : [], 'job_url' : []}\n",
    "target_job_url = 'https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/{}/' #format of the URL. The {} is where the jobID gets formated to.\n",
    "for i in range(0, len(job_ids_list)): # Main loop\n",
    "    res_job = requests.get(target_job_url.format(job_ids_list[i]))\n",
    "    if res_job.status_code != 200:\n",
    "        print('Status code not 200. Sleeping for 1 minute')\n",
    "        time.sleep(60) #Long sleep in case of IP block\n",
    "    else:\n",
    "        soup = BeautifulSoup(res_job.text, 'html.parser')\n",
    "        try:\n",
    "            df['job_title'].append(soup.find('div',{'class':'top-card-layout__entity-info'}).find('a').text.strip()) #Title\n",
    "        except:\n",
    "            df['job_title'].append(None)\n",
    "        try:\n",
    "            df['company'].append(soup.find('div',{'class':'top-card-layout__card'}).find('a').find('img').get('alt')) #Company\n",
    "        except:\n",
    "            df['company'].append(None)\n",
    "        try:\n",
    "            df['job_info'].append(soup.find('div',{'class':'show-more-less-html__markup'}).text.strip()) #Bulk, might need to find a way to clean this up.\n",
    "        except:\n",
    "            df['job_info'].append(None)\n",
    "        try:\n",
    "            df['when_posted'].append(soup.find('span',{'class':'posted-time-ago__text'}).text.replace('\\n', '').strip()) #When was it posted\n",
    "        except:\n",
    "            df['when_posted'].append(None)\n",
    "        num_of_apps1 = soup.find('figcaption',{'class':'num-applicants__caption'})  #number of applicants scape attempt1\n",
    "        if num_of_apps1 == None: #Check first soup, if it fails check second soup\n",
    "            num_of_apps2 = soup.find('span', class_='num-applicants__caption topcard__flavor--metadata topcard__flavor--bullet') #number of applicants scrape attempt2\n",
    "            if num_of_apps2 == None: #Check second soup, if it fails, append None\n",
    "                df['num_applicants'].append(None) #if nosoup works just append None\n",
    "            else:\n",
    "                df['num_applicants'].append(num_of_apps2.text.replace('\\n', '').strip()) #If first soup failed and second soup passed, append second soup\n",
    "        else:\n",
    "            df['num_applicants'].append(num_of_apps1.text.replace('\\n', '').strip()) #If first soup works, append first soup\n",
    "        job_attributes = soup.find('ul',{'class':'description__job-criteria-list'}) #Job attributes\n",
    "        if job_attributes == None: #Check to see if there is soup. If not, append none.\n",
    "            df['seniority'].append(None)\n",
    "            df['employment_type'].append(None)\n",
    "            df['job_function'].append(None)\n",
    "            df['industry'].append(None)\n",
    "        else:\n",
    "            job_attributes = job_attributes.text.replace('\\n', '').strip()\n",
    "            if 'Seniority level' in job_attributes:\n",
    "                pattern = 'Seniority level\\s+(?P<seniority>(.*?)(?:\\s{2,}|$))'\n",
    "                df['seniority'].append(re.search(pattern, job_attributes).groups()[0])\n",
    "            else:\n",
    "                df['seniority'].append(None)\n",
    "            if 'Employment type' in job_attributes:\n",
    "                pattern = 'Employment type\\s+(?P<employment_type>(.*?)(?:\\s{2,}|$))'\n",
    "                df['employment_type'].append(re.search(pattern, job_attributes).groups()[0])\n",
    "            else:\n",
    "                df['employment_type'].append(None)\n",
    "            if 'Job function' in job_attributes:\n",
    "                pattern = 'Job function\\s+(?P<job_function>(.*?)(?:\\s{2,}|$))'\n",
    "                df['job_function'].append(re.search(pattern, job_attributes).groups()[0])\n",
    "            else:\n",
    "                df['job_function'].append(None)\n",
    "            if 'Industries' in job_attributes:\n",
    "                pattern = 'Industries\\s+(?P<industries>(.*?)(?:\\s{2,}|$))'\n",
    "                df['industry'].append(re.search(pattern, job_attributes).groups()[0])\n",
    "            else:\n",
    "                df['industry'].append(None)\n",
    "        clear_output()\n",
    "        print(f'Obatined info for id: {job_ids_list[i]}')\n",
    "        df['job_url'].append(f'https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/{job_ids_list[0]}/')\n",
    "        job_ids_list.pop(0)\n",
    "        time.sleep(random.choice(range(2,4,1))) # Sleep to avoid IP block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa3b496-a2cf-499b-bcf3-ced5e67a713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6ea047b-2e9e-4b37-9fab-093e542d7c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   job_title        5 non-null      object\n",
      " 1   company          5 non-null      object\n",
      " 2   job_info         5 non-null      object\n",
      " 3   when_posted      5 non-null      object\n",
      " 4   num_applicants   5 non-null      object\n",
      " 5   seniority        5 non-null      object\n",
      " 6   employment_type  5 non-null      object\n",
      " 7   job_function     5 non-null      object\n",
      " 8   industry         5 non-null      object\n",
      " 9   job_id           5 non-null      object\n",
      "dtypes: object(10)\n",
      "memory usage: 532.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6cf3b51f-bee5-49bd-ade2-73ac731e380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_scrape(job_dict: dict, job_id_list: list) -> tuple[dict, list]:\n",
    "    if job_dict == {}:\n",
    "        job_dict = {'job_title' : [], 'company' : [], 'job_info' : [], 'when_posted' : [], 'num_applicants' : [],\n",
    "      'seniority' : [], 'employment_type' : [], 'job_function' : [], 'industry' : [], 'job_url' : []}\n",
    "    else:\n",
    "        pass\n",
    "    target_job_url = 'https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/{}/' #format of the URL. The {} is where the jobID gets formated to.\n",
    "    res_job = requests.get(target_job_url.format(job_ids_list[0]))\n",
    "    if res_job.status_code != 200:\n",
    "        print('Status code not 200. Sleeping for 1 minute')\n",
    "        time.sleep(60) #Long sleep in case of IP block\n",
    "    else:\n",
    "        soup = BeautifulSoup(res_job.text, 'html.parser')\n",
    "        try:\n",
    "            job_dict['job_title'].append(soup.find('div',{'class':'top-card-layout__entity-info'}).find('a').text.strip()) #Title\n",
    "        except:\n",
    "            job_dict['job_title'].append(None)\n",
    "        try:\n",
    "            job_dict['company'].append(soup.find('div',{'class':'top-card-layout__card'}).find('a').find('img').get('alt')) #Company\n",
    "        except:\n",
    "            job_dict['company'].append(None)\n",
    "        try:\n",
    "            job_dict['job_info'].append(soup.find('div',{'class':'show-more-less-html__markup'}).text.strip()) #Bulk, might need to find a way to clean this up.\n",
    "        except:\n",
    "            job_dict['job_info'].append(None)\n",
    "        try:\n",
    "            job_dict['when_posted'].append(soup.find('span',{'class':'posted-time-ago__text'}).text.replace('\\n', '').strip()) #When was it posted\n",
    "        except:\n",
    "            job_dict['when_posted'].append(None)\n",
    "        num_of_apps1 = soup.find('figcaption',{'class':'num-applicants__caption'})  #number of applicants scape attempt1\n",
    "        if num_of_apps1 == None: #Check first soup, if it fails check second soup\n",
    "            num_of_apps2 = soup.find('span', class_='num-applicants__caption topcard__flavor--metadata topcard__flavor--bullet') #number of applicants scrape attempt2\n",
    "            if num_of_apps2 == None: #Check second soup, if it fails, append None\n",
    "                job_dict['num_applicants'].append(None) #if nosoup works just append None\n",
    "            else:\n",
    "                job_dict['num_applicants'].append(num_of_apps2.text.replace('\\n', '').strip()) #If first soup failed and second soup passed, append second soup\n",
    "        else:\n",
    "            job_dict['num_applicants'].append(num_of_apps1.text.replace('\\n', '').strip()) #If first soup works, append first soup\n",
    "        job_attributes = soup.find('ul',{'class':'description__job-criteria-list'}) #Job attributes\n",
    "        if job_attributes == None: #Check to see if there is soup. If not, append none.\n",
    "            job_dict['seniority'].append(None)\n",
    "            job_dict['employment_type'].append(None)\n",
    "            job_dict['job_function'].append(None)\n",
    "            job_dict['industry'].append(None)\n",
    "        else:\n",
    "            job_attributes = job_attributes.text.replace('\\n', '').strip()\n",
    "            if 'Seniority level' in job_attributes:\n",
    "                pattern = 'Seniority level\\s+(?P<seniority>(.*?)(?:\\s{2,}|$))'\n",
    "                job_dict['seniority'].append(re.search(pattern, job_attributes).groups()[0])\n",
    "            else:\n",
    "                job_dict['seniority'].append(None)\n",
    "            if 'Employment type' in job_attributes:\n",
    "                pattern = 'Employment type\\s+(?P<employment_type>(.*?)(?:\\s{2,}|$))'\n",
    "                job_dict['employment_type'].append(re.search(pattern, job_attributes).groups()[0])\n",
    "            else:\n",
    "                job_dict['employment_type'].append(None)\n",
    "            if 'Job function' in job_attributes:\n",
    "                pattern = 'Job function\\s+(?P<job_function>(.*?)(?:\\s{2,}|$))'\n",
    "                job_dict['job_function'].append(re.search(pattern, job_attributes).groups()[0])\n",
    "            else:\n",
    "                job_dict['job_function'].append(None)\n",
    "            if 'Industries' in job_attributes:\n",
    "                pattern = 'Industries\\s+(?P<industries>(.*?)(?:\\s{2,}|$))'\n",
    "                job_dict['industry'].append(re.search(pattern, job_attributes).groups()[0])\n",
    "            else:\n",
    "                job_dict['industry'].append(None)\n",
    "        job_dict['job_url'].append(f'https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/{job_ids_list[0]}/')\n",
    "        job_ids_list.pop(0)\n",
    "        time.sleep(random.choice(range(2,4,1))) # Sleep to avoid IP block\n",
    "    return job_dict, job_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "45d5a1e8-2e6d-47d2-ba15-d3704ee69a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "950"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe6b47a3-e53f-49af-871e-3a12af6213bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#job_data = {}\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(job_ids_list)):\n\u001b[0;32m----> 3\u001b[0m     job_data, job_ids_list \u001b[38;5;241m=\u001b[39m \u001b[43mjob_scrape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_ids_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[30], line 69\u001b[0m, in \u001b[0;36mjob_scrape\u001b[0;34m(job_dict, job_id_list)\u001b[0m\n\u001b[1;32m     67\u001b[0m     job_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob_url\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.linkedin.com/jobs-guest/jobs/api/jobPosting/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob_ids_list[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     68\u001b[0m     job_ids_list\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(random\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m1\u001b[39m))) \u001b[38;5;66;03m# Sleep to avoid IP block\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m job_dict, job_id_list\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#job_data = {}\n",
    "for i in range(0, len(job_ids_list)):\n",
    "    job_data, job_ids_list = job_scrape(job_data, job_ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "01cba971-0fb1-44bb-bdb2-6b6ff0985f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>job_info</th>\n",
       "      <th>when_posted</th>\n",
       "      <th>num_applicants</th>\n",
       "      <th>seniority</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_function</th>\n",
       "      <th>industry</th>\n",
       "      <th>job_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Harnham</td>\n",
       "      <td>Senior Data ScientistHealthcare | United State...</td>\n",
       "      <td>4 hours ago</td>\n",
       "      <td>53 applicants</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Information Technology and Health Care Provide...</td>\n",
       "      <td>Hospitals and Health Care</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python/R Developer</td>\n",
       "      <td>Sonitalent Corp</td>\n",
       "      <td>Role: Python/R DeveloperLocation:100% remote(W...</td>\n",
       "      <td>23 hours ago</td>\n",
       "      <td>Over 200 applicants</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology        ...</td>\n",
       "      <td>Staffing and Recruiting</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Qventus, Inc</td>\n",
       "      <td>The CompanyHave you ever found yourself or a l...</td>\n",
       "      <td>13 hours ago</td>\n",
       "      <td>84 applicants</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology        ...</td>\n",
       "      <td>Hospitals and Health Care</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Staff Data Scientist</td>\n",
       "      <td>Machinify, Inc.</td>\n",
       "      <td>Machinify is a revolutionary healthcare softwa...</td>\n",
       "      <td>20 hours ago</td>\n",
       "      <td>Be among the first 25 applicants</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology        ...</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Python Developer - Remote | WFH</td>\n",
       "      <td>Get It Recruit - Information Technology</td>\n",
       "      <td>Are you ready to embark on a journey with a pi...</td>\n",
       "      <td>15 hours ago</td>\n",
       "      <td>48 applicants</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology        ...</td>\n",
       "      <td>Human Resources Services</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>ManTech</td>\n",
       "      <td>Secure our Nation, Ignite your FutureData Scie...</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>28 applicants</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology        ...</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Clinical Data Scientist, Real-World Dat...</td>\n",
       "      <td>Freenome</td>\n",
       "      <td>Why join Freenome?Freenome is a high-growth bi...</td>\n",
       "      <td>12 hours ago</td>\n",
       "      <td>36 applicants</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology        ...</td>\n",
       "      <td>Biotechnology Research</td>\n",
       "      <td>https://www.linkedin.com/jobs-guest/jobs/api/j...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0                              Senior Data Scientist   \n",
       "1                                 Python/R Developer   \n",
       "2                              Senior Data Scientist   \n",
       "3                               Staff Data Scientist   \n",
       "4                    Python Developer - Remote | WFH   \n",
       "5                                     Data Scientist   \n",
       "6  Senior Clinical Data Scientist, Real-World Dat...   \n",
       "\n",
       "                                   company  \\\n",
       "0                                  Harnham   \n",
       "1                          Sonitalent Corp   \n",
       "2                             Qventus, Inc   \n",
       "3                          Machinify, Inc.   \n",
       "4  Get It Recruit - Information Technology   \n",
       "5                                  ManTech   \n",
       "6                                 Freenome   \n",
       "\n",
       "                                            job_info   when_posted  \\\n",
       "0  Senior Data ScientistHealthcare | United State...   4 hours ago   \n",
       "1  Role: Python/R DeveloperLocation:100% remote(W...  23 hours ago   \n",
       "2  The CompanyHave you ever found yourself or a l...  13 hours ago   \n",
       "3  Machinify is a revolutionary healthcare softwa...  20 hours ago   \n",
       "4  Are you ready to embark on a journey with a pi...  15 hours ago   \n",
       "5  Secure our Nation, Ignite your FutureData Scie...   6 hours ago   \n",
       "6  Why join Freenome?Freenome is a high-growth bi...  12 hours ago   \n",
       "\n",
       "                     num_applicants                             seniority  \\\n",
       "0                     53 applicants  Mid-Senior level                       \n",
       "1               Over 200 applicants       Entry level                       \n",
       "2                     84 applicants  Mid-Senior level                       \n",
       "3  Be among the first 25 applicants       Entry level                       \n",
       "4                     48 applicants       Entry level                       \n",
       "5                     28 applicants       Entry level                       \n",
       "6                     36 applicants  Mid-Senior level                       \n",
       "\n",
       "                 employment_type  \\\n",
       "0  Full-time                       \n",
       "1  Full-time                       \n",
       "2  Full-time                       \n",
       "3  Full-time                       \n",
       "4  Full-time                       \n",
       "5  Full-time                       \n",
       "6  Full-time                       \n",
       "\n",
       "                                        job_function  \\\n",
       "0  Information Technology and Health Care Provide...   \n",
       "1  Engineering and Information Technology        ...   \n",
       "2  Engineering and Information Technology        ...   \n",
       "3  Engineering and Information Technology        ...   \n",
       "4  Engineering and Information Technology        ...   \n",
       "5  Engineering and Information Technology        ...   \n",
       "6  Engineering and Information Technology        ...   \n",
       "\n",
       "                        industry  \\\n",
       "0      Hospitals and Health Care   \n",
       "1        Staffing and Recruiting   \n",
       "2      Hospitals and Health Care   \n",
       "3           Software Development   \n",
       "4       Human Resources Services   \n",
       "5  IT Services and IT Consulting   \n",
       "6         Biotechnology Research   \n",
       "\n",
       "                                             job_url  \n",
       "0  https://www.linkedin.com/jobs-guest/jobs/api/j...  \n",
       "1  https://www.linkedin.com/jobs-guest/jobs/api/j...  \n",
       "2  https://www.linkedin.com/jobs-guest/jobs/api/j...  \n",
       "3  https://www.linkedin.com/jobs-guest/jobs/api/j...  \n",
       "4  https://www.linkedin.com/jobs-guest/jobs/api/j...  \n",
       "5  https://www.linkedin.com/jobs-guest/jobs/api/j...  \n",
       "6  https://www.linkedin.com/jobs-guest/jobs/api/j...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(job_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f17b6c4d-26b4-4b18-a1af-7f524f32e6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d50a891-8bc5-4e6e-aa06-68187a65c4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b317739-4df0-4e2a-beb5-0467c8b37ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [test]\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.assign(test = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afaae608-7053-43e9-bab6-fb67f4c0fe0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4482c956-53db-4f84-b2c8-3dc78a01b835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envlinkedin",
   "language": "python",
   "name": "envlinkedin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
